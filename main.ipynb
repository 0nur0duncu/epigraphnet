{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8899c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!rm -rf epigraphnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6c56742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'epigraphnet'...\n",
      "remote: Enumerating objects: 559, done.\u001b[K\n",
      "remote: Counting objects: 100% (559/559), done.\u001b[K\n",
      "remote: Compressing objects: 100% (546/546), done.\u001b[K\n",
      "remote: Total 559 (delta 13), reused 558 (delta 12), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (559/559), 2.75 MiB | 6.04 MiB/s, done.\n",
      "Resolving deltas: 100% (13/13), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/0nur0duncu/epigraphnet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd73ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 9, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (5/5), 3.84 KiB | 1.28 MiB/s, done.\n",
      "From https://github.com/0nur0duncu/epigraphnet\n",
      "   be267e5..1db5855  main       -> origin/main\n",
      "Updating be267e5..1db5855\n",
      "Fast-forward\n",
      " data/download_bonn.py |  40 \u001b[32m++++++++\u001b[m\u001b[31m---\u001b[m\n",
      " main.ipynb            | 193 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m---\u001b[m\n",
      " 2 files changed, 212 insertions(+), 21 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f3545b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/epigraphnet\n"
     ]
    }
   ],
   "source": [
    "%cd epigraphnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7dae34",
   "metadata": {},
   "source": [
    "## 2. Dizin DeÄŸiÅŸtirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee1c1b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.24.0+cu126)\n",
      "Requirement already satisfied: torch-geometric>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.0.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (1.16.3)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (6.0.3)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (3.10.0)\n",
      "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (1.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (2.19.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.15.0->-r requirements.txt (line 6)) (11.3.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.4.0->-r requirements.txt (line 9)) (3.13.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.4.0->-r requirements.txt (line 9)) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.4.0->-r requirements.txt (line 9)) (3.2.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.4.0->-r requirements.txt (line 9)) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric>=2.4.0->-r requirements.txt (line 9)) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 13)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 13)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 13)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 20)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 20)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 20)) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 20)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 20)) (25.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 27)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 27)) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 30)) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 30)) (1.76.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 30)) (3.10)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 30)) (5.29.5)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 30)) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 30)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.14.0->-r requirements.txt (line 30)) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.14.0->-r requirements.txt (line 30)) (3.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric>=2.4.0->-r requirements.txt (line 9)) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a282744",
   "metadata": {},
   "source": [
    "## 3. BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff18530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Bonn Epileptik EEG Veri KÃ¼mesi Ä°ndirme\n",
      "Kaynak: Bonn Ãœniversitesi Epileptoloji\n",
      "============================================================\n",
      "\n",
      "[Z] Set indiriliyor...\n",
      "\n",
      "  âœ“ Ä°ndirme tamamlandÄ±!\n",
      "Ã‡Ä±karÄ±lÄ±yor: data/bonn/Z.zip\n",
      "  âœ— Ã‡Ä±karma hatasÄ±: File is not a zip file\n",
      "\n",
      "[O] Set indiriliyor...\n",
      "\n",
      "  âœ“ Ä°ndirme tamamlandÄ±!\n",
      "Ã‡Ä±karÄ±lÄ±yor: data/bonn/O.zip\n",
      "  âœ— Ã‡Ä±karma hatasÄ±: File is not a zip file\n",
      "\n",
      "[N] Set indiriliyor...\n",
      "\n",
      "  âœ“ Ä°ndirme tamamlandÄ±!\n",
      "Ã‡Ä±karÄ±lÄ±yor: data/bonn/N.zip\n",
      "  âœ— Ã‡Ä±karma hatasÄ±: File is not a zip file\n",
      "\n",
      "[F] Set indiriliyor...\n",
      "\n",
      "  âœ“ Ä°ndirme tamamlandÄ±!\n",
      "Ã‡Ä±karÄ±lÄ±yor: data/bonn/F.zip\n",
      "  âœ— Ã‡Ä±karma hatasÄ±: File is not a zip file\n",
      "\n",
      "[S] Set indiriliyor...\n",
      "\n",
      "  âœ“ Ä°ndirme tamamlandÄ±!\n",
      "Ã‡Ä±karÄ±lÄ±yor: data/bonn/S.zip\n",
      "  âœ— Ã‡Ä±karma hatasÄ±: File is not a zip file\n",
      "\n",
      "============================================================\n",
      "UYARI: BazÄ± setler indirilemedi: ['Z', 'O', 'N', 'F', 'S']\n",
      "Manuel indirme iÃ§in: https://www.upf.edu/web/ntsa/downloads\n",
      "\n",
      "==================================================\n",
      "BONN EEG VERÄ° KÃœMESÄ° BÄ°LGÄ°LERÄ°\n",
      "==================================================\n",
      "Toplam dosya: 400\n",
      "Sinyal uzunluÄŸu: 4097 nokta\n",
      "Ã–rnekleme frekansÄ±: 173.61 Hz\n",
      "KayÄ±t sÃ¼resi: 23.6 saniye\n",
      "\n",
      "SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±:\n",
      "----------------------------------------\n",
      "  Z: 100 dosya - SaÄŸlÄ±klÄ± (gÃ¶zler aÃ§Ä±k)\n",
      "  O: 100 dosya - SaÄŸlÄ±klÄ± (gÃ¶zler kapalÄ±)\n",
      "  N:   0 dosya - Epilepsi (nÃ¶tr)\n",
      "  F: 100 dosya - Epilepsi (uyaran)\n",
      "  S: 100 dosya - NÃ¶bet\n",
      "\n",
      "âœ— UYARI: Eksik dosya! Beklenen: 500, Bulunan: 400\n"
     ]
    }
   ],
   "source": [
    "!python data/download_bonn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e584165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ N SETÄ°NÄ° TEK BAÅINA Ä°NDÄ°R VE DÃœZELT\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"N SETÄ° Ã–ZEL Ä°NDÄ°RME VE DÃœZELTME\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data_dir = \"data/bonn\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# N seti URL'si (UPF NTSA)\n",
    "n_url = \"https://www.upf.edu/documents/229517819/234490509/N.zip/d4f08e2d-3b27-1a6a-20fe-96dcf644902b\"\n",
    "n_zip = os.path.join(data_dir, \"N.zip\")\n",
    "\n",
    "print(f\"\\nğŸ“¥ N.zip indiriliyor...\")\n",
    "try:\n",
    "    req = urllib.request.Request(\n",
    "        n_url,\n",
    "        headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
    "    )\n",
    "    \n",
    "    with urllib.request.urlopen(req, timeout=120) as response:\n",
    "        with open(n_zip, 'wb') as f:\n",
    "            f.write(response.read())\n",
    "    \n",
    "    print(\"âœ… Ä°ndirme tamamlandÄ±!\")\n",
    "    \n",
    "    # ZIP iÃ§eriÄŸini kontrol et\n",
    "    print(f\"\\nğŸ“¦ ZIP iÃ§eriÄŸi kontrol ediliyor...\")\n",
    "    with zipfile.ZipFile(n_zip, 'r') as zip_ref:\n",
    "        file_list = zip_ref.namelist()\n",
    "        print(f\"   â€¢ Toplam {len(file_list)} Ã¶ÄŸe bulundu\")\n",
    "        \n",
    "        # Ä°lk birkaÃ§ dosyayÄ± gÃ¶ster\n",
    "        print(f\"   â€¢ Ä°lk 3 Ã¶ÄŸe: {file_list[:3]}\")\n",
    "        \n",
    "        # TÃ¼m dosyalarÄ± Ã§Ä±kar\n",
    "        print(f\"\\nğŸ”„ Dosyalar Ã§Ä±karÄ±lÄ±yor...\")\n",
    "        zip_ref.extractall(data_dir)\n",
    "        \n",
    "        # DosyalarÄ± dÃ¼zenle (alt klasÃ¶rlerden taÅŸÄ±)\n",
    "        n_count = 0\n",
    "        for item in file_list:\n",
    "            # Dosya adÄ±nÄ± al\n",
    "            if item.endswith('.txt'):\n",
    "                filename = os.path.basename(item)\n",
    "                \n",
    "                # EÄŸer N ile baÅŸlÄ±yorsa\n",
    "                if filename.startswith('N'):\n",
    "                    # Kaynak yol\n",
    "                    if '/' in item or '\\\\' in item:\n",
    "                        src = os.path.join(data_dir, item)\n",
    "                    else:\n",
    "                        src = os.path.join(data_dir, filename)\n",
    "                    \n",
    "                    # Hedef yol (data/bonn/ altÄ±na direkt)\n",
    "                    dst = os.path.join(data_dir, filename)\n",
    "                    \n",
    "                    # TaÅŸÄ± (eÄŸer farklÄ± konumlardaysa)\n",
    "                    if os.path.exists(src) and src != dst:\n",
    "                        shutil.move(src, dst)\n",
    "                    \n",
    "                    n_count += 1\n",
    "        \n",
    "        print(f\"âœ… {n_count} N dosyasÄ± Ã§Ä±karÄ±ldÄ±!\")\n",
    "        \n",
    "    # ZIP'i sil\n",
    "    os.remove(n_zip)\n",
    "    print(f\"ğŸ—‘ï¸  N.zip silindi\")\n",
    "    \n",
    "    # Alt klasÃ¶rleri temizle\n",
    "    for item in os.listdir(data_dir):\n",
    "        item_path = os.path.join(data_dir, item)\n",
    "        if os.path.isdir(item_path) and item not in ['__pycache__']:\n",
    "            try:\n",
    "                shutil.rmtree(item_path)\n",
    "                print(f\"   ğŸ—‘ï¸  Alt klasÃ¶r silindi: {item}\")\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ HATA: {e}\")\n",
    "    print(\"\\nğŸ’¡ Manuel indirme:\")\n",
    "    print(\"   1. https://www.upf.edu/web/ntsa/downloads\")\n",
    "    print(\"   2. Set C (N.zip) indir\")\n",
    "    print(\"   3. data/bonn/ klasÃ¶rÃ¼ne Ã§Ä±kar\")\n",
    "\n",
    "# FÄ°NAL KONTROL\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FÄ°NAL KONTROL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "total = 0\n",
    "for cls in ['S', 'N', 'F', 'O', 'Z']:\n",
    "    cls_files = [f for f in os.listdir(data_dir) if f.startswith(cls) and f.endswith('.txt')]\n",
    "    print(f\"{cls} sÄ±nÄ±fÄ±: {len(cls_files)} dosya\")\n",
    "    total += len(cls_files)\n",
    "\n",
    "if total == 500:\n",
    "    print(f\"\\nâœ… BAÅARILI! TOPLAM: {total}/500 dosya\")\n",
    "    print(\"ğŸ‘‰ ArtÄ±k HÃ¼cre 10'u (EÄŸitim) Ã§alÄ±ÅŸtÄ±rabilirsiniz!\")\n",
    "else:\n",
    "    print(f\"\\nâŒ EKSÄ°K! TOPLAM: {total}/500 dosya\")\n",
    "    print(\"âš ï¸  N seti hÃ¢lÃ¢ eksikse manuel indirme gerekli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de906630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EÄŸitimi baÅŸlat\n",
    "# UYARI: Ä°lk Ã§alÄ±ÅŸtÄ±rmada Bonn veri kÃ¼mesi otomatik indirilecektir\n",
    "!python train.py --config config/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3926b",
   "metadata": {},
   "source": [
    "## 4. Model EÄŸitimi\n",
    "\n",
    "**Makaledeki Tablo I parametreleriyle eÄŸitim:**\n",
    "- Dataset: Bonn EEG (500 Ã¶rnek, 5 sÄ±nÄ±f)\n",
    "- Batch Size: 64\n",
    "- Learning Rate: 0.001\n",
    "- Epochs: 50 (Early Stopping: Patience=10)\n",
    "- Optimizer: Adam (weight_decay=0.0005)\n",
    "\n",
    "**UYARI:** \n",
    "- â±ï¸ EÄŸitim sÃ¼resi: GPU'da ~10-30 dakika, CPU'da 1-2 saat\n",
    "- ğŸ’¾ Ä°lk Ã§alÄ±ÅŸtÄ±rmada Bonn veri kÃ¼mesi otomatik indirilir (~15MB)\n",
    "- ğŸ“Š En iyi model `checkpoints/best_model.pt` olarak kaydedilir\n",
    "\n",
    "**Beklenen DavranÄ±ÅŸ:**\n",
    "- Her epoch'ta Train ve Val metrikleri gÃ¶rÃ¼ntÃ¼lenir\n",
    "- Loss azalÄ±rken Accuracy artmalÄ±dÄ±r\n",
    "- Early stopping devreye girebilir (validation loss dÃ¼zelmezse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a323807",
   "metadata": {},
   "outputs": [],
   "source": [
    "!!python evaluate.py --num-runs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fdc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makaledeki gibi 5 kez Ã§alÄ±ÅŸtÄ±rÄ±p ortalama ve standart sapma hesapla\n",
    "!python evaluate.py --checkpoint checkpoints/best_model.pt --num-runs 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96453b44",
   "metadata": {},
   "source": [
    "### âš ï¸ DURUM: Checkpoint Eski Mimariyle EÄŸitilmiÅŸ\n",
    "\n",
    "**Checkpoint Bilgisi:**\n",
    "- Epoch: 17\n",
    "- Val Accuracy: 70%\n",
    "- **Sorun:** Eski model mimarisi ile kaydedilmiÅŸ\n",
    "\n",
    "**Hata:**\n",
    "```\n",
    "RuntimeError: Unexpected key(s) in state_dict\n",
    "```\n",
    "\n",
    "**Sebep:** Checkpoint'teki katman isimleri (gcn.gcn_layers.X.conv.lin_rel) yeni kod ile uyumsuz\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Ã‡Ã–ZÃœM: YENÄ° MÄ°MARÄ°YLE EÄÄ°T\n",
    "\n",
    "### ğŸ”´ 1. CHECKPOINT'Ä° SÄ°L (HÃ¼cre 14 - Hemen aÅŸaÄŸÄ±da)\n",
    "Eski checkpoint'i silmek iÃ§in aÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n â¬‡ï¸\n",
    "\n",
    "### ğŸ”µ 2. YENÄ°DEN EÄÄ°T (HÃ¼cre 8)\n",
    "Modeli yeni mimariyle baÅŸtan eÄŸitin (Scroll up â†’ HÃ¼cre 8)\n",
    "```python\n",
    "!python train.py --config config/config.yaml\n",
    "```\n",
    "â±ï¸ **SÃ¼re:** 10-30 dakika (GPU), 1-2 saat (CPU)  \n",
    "ğŸ“Š **Hedef:** Val Accuracy > 80% (ÅŸu an eski checkpoint 70%)\n",
    "\n",
    "### ğŸŸ¢ 3. DEÄERLENDÄ°R (HÃ¼cre 12)\n",
    "EÄŸitim bittikten sonra bu hÃ¼creyi (HÃ¼cre 12) tekrar Ã§alÄ±ÅŸtÄ±rÄ±n\n",
    "```python\n",
    "!python evaluate.py --checkpoint checkpoints/best_model.pt --num-runs 5\n",
    "```\n",
    "ğŸ¯ **Beklenen:** Accuracy 90-95%+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39743da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”´ ADI M 1: ESKÄ° CHECKPOINT'Ä° SÄ°L\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ESKÄ° CHECKPOINT BÄ°LGÄ°SÄ°:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Epoch: 17\")\n",
    "print(\"Val Accuracy: 70%\")\n",
    "print(\"Durum: Eski mimariyle eÄŸitilmiÅŸ, yeni kod ile UYUMSUZ\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nğŸ—‘ï¸  Siliniyor...\\n\")\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "    print(\"âœ… Eski checkpoint silindi!\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SIRADAKÄ° ADIM:\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"â¬†ï¸  Scroll up â†’ HÃ¼cre 8'i Ã§alÄ±ÅŸtÄ±rÄ±n\")\n",
    "    print(\"ğŸ“ Komut: !python train.py --config config/config.yaml\")\n",
    "    print(\"â±ï¸  SÃ¼re: GPU'da 10-30 dakika\")\n",
    "    print(\"ğŸ¯ Hedef: Val Accuracy > 80% (ÅŸu an 70%)\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"â„¹ï¸  Checkpoint dizini zaten yok\")\n",
    "    print(\"\\nâ¬†ï¸  HÃ¼cre 8'i (Model EÄŸitimi) Ã§alÄ±ÅŸtÄ±rÄ±n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc8e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” CHECKPOINT Ä°Ã‡ERÄ°ÄÄ°NÄ° KONTROL ET\n",
    "import torch\n",
    "import os\n",
    "\n",
    "checkpoint_path = \"checkpoints/best_model.pt\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"ğŸ“‚ Checkpoint bulundu!\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CHECKPOINT BÄ°LGÄ°LERÄ°:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    print(f\"Val Accuracy: {checkpoint.get('val_accuracy', 'N/A'):.2f}%\")\n",
    "    print(f\"Val Loss: {checkpoint.get('val_loss', 'N/A'):.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL MÄ°MARÄ°SÄ° ANAHTARLARI (Ä°lk 10):\")\n",
    "    print(\"=\"*60)\n",
    "    model_keys = list(checkpoint['model_state_dict'].keys())[:10]\n",
    "    for key in model_keys:\n",
    "        print(f\"  â€¢ {key}\")\n",
    "    \n",
    "    # Eski mimari kontrolÃ¼\n",
    "    old_arch_markers = [\n",
    "        \"gcn.gcn_layers.0.conv.lin_rel\",\n",
    "        \"gcn.fc.weight\",\n",
    "        \"cnn_lstm.cnn.fc.weight\"\n",
    "    ]\n",
    "    \n",
    "    is_old = any(key in checkpoint['model_state_dict'] for key in old_arch_markers)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    if is_old:\n",
    "        print(\"âŒ ESKÄ° MÄ°MARÄ° ALGILANDI!\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nğŸ”´ SORUN: GitHub repo kodu hÃ¢lÃ¢ eski!\")\n",
    "        print(\"\\nâœ… Ã‡Ã–ZÃœM:\")\n",
    "        print(\"1. GitHub repo'yu kontrol edin\")\n",
    "        print(\"2. !git pull origin main yapÄ±n (HÃ¼cre 10)\")\n",
    "        print(\"3. Checkpoint'i tekrar silin (Bu hÃ¼cre - 14)\")\n",
    "        print(\"4. EÄŸitimi tekrar baÅŸlatÄ±n (HÃ¼cre 8)\")\n",
    "    else:\n",
    "        print(\"âœ… YENÄ° MÄ°MARÄ° DOÄRULANDI!\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\nğŸ¯ Checkpoint artÄ±k yeni kod ile uyumlu!\")\n",
    "        print(\"ğŸ‘‰ HÃ¼cre 12'yi Ã§alÄ±ÅŸtÄ±rabilirsiniz\")\n",
    "else:\n",
    "    print(\"âŒ Checkpoint bulunamadÄ±!\")\n",
    "    print(\"ğŸ‘‰ HÃ¼cre 8'i (EÄŸitim) Ã§alÄ±ÅŸtÄ±rÄ±n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4807bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ PYTHON KODLARINI KONTROL ET\n",
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"YEREL DOSYA KONTROLÃœ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# GCN modÃ¼lÃ¼nÃ¼ kontrol et\n",
    "gcn_file = \"models/gcn_module.py\"\n",
    "if os.path.exists(gcn_file):\n",
    "    with open(gcn_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Eski mimari iÅŸaretleri\n",
    "    has_old_rgcn = \"RGCNConv\" in content\n",
    "    has_old_fc = \"self.fc = nn.Linear\" in content and \"self.gcn_layers\" in content\n",
    "    \n",
    "    print(f\"\\nğŸ“„ {gcn_file}:\")\n",
    "    if has_old_rgcn or has_old_fc:\n",
    "        print(\"  âŒ ESKÄ° KOD BULUNDU!\")\n",
    "        if has_old_rgcn:\n",
    "            print(\"     - RGCNConv kullanÄ±lÄ±yor (eski)\")\n",
    "        if has_old_fc:\n",
    "            print(\"     - AyrÄ± FC katmanÄ± var (eski)\")\n",
    "    else:\n",
    "        print(\"  âœ… YENÄ° KOD\")\n",
    "else:\n",
    "    print(f\"âŒ {gcn_file} bulunamadÄ±!\")\n",
    "\n",
    "# CNN modÃ¼lÃ¼nÃ¼ kontrol et  \n",
    "cnn_file = \"models/cnn_module.py\"\n",
    "if os.path.exists(cnn_file):\n",
    "    with open(cnn_file, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    has_old_fc = \"self.fc = nn.Linear\" in content\n",
    "    \n",
    "    print(f\"\\nğŸ“„ {cnn_file}:\")\n",
    "    if has_old_fc:\n",
    "        print(\"  âŒ ESKÄ° KOD - FC katmanÄ± var (eski mimari)\")\n",
    "    else:\n",
    "        print(\"  âœ… YENÄ° KOD - FC katmanÄ± yok\")\n",
    "else:\n",
    "    print(f\"âŒ {cnn_file} bulunamadÄ±!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š SONUÃ‡:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nEÄŸer yukarÄ±da 'âŒ ESKÄ° KOD' gÃ¶rÃ¼yorsanÄ±z:\")\n",
    "print(\"1. GitHub'da kodlarÄ±n gÃ¼ncel olup olmadÄ±ÄŸÄ±nÄ± kontrol edin\")\n",
    "print(\"2. Repo'yu silip yeniden klonlayÄ±n:\")\n",
    "print(\"   !rm -rf epigraphnet\")\n",
    "print(\"   !git clone https://github.com/0nur0duncu/epigraphnet.git\")\n",
    "print(\"3. %cd epigraphnet\")\n",
    "print(\"4. Checkpoint'i silin (HÃ¼cre 14)\")\n",
    "print(\"5. EÄŸitimi baÅŸlatÄ±n (HÃ¼cre 8)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad0112",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš ï¸ YAPILACAKLAR LÄ°STESÄ°\n",
    "\n",
    "### âœ… AdÄ±m 1: CHECKPOINT SÄ°L\n",
    "**YukarÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n** â¬†ï¸\n",
    "\n",
    "### ğŸ“ AdÄ±m 2: MODELÄ° YENÄ°DEN EÄÄ°T  \n",
    "**HÃ¼cre 8'i Ã§alÄ±ÅŸtÄ±rÄ±n** (scroll up)\n",
    "```python\n",
    "!python train.py --config config/config.yaml\n",
    "```\n",
    "â±ï¸ SÃ¼re: GPU'da 10-30 dakika\n",
    "\n",
    "### ğŸ¯ AdÄ±m 3: DEÄERLENDÄ°R\n",
    "**HÃ¼cre 11'i Ã§alÄ±ÅŸtÄ±rÄ±n** (eÄŸitim bittikten sonra)\n",
    "```python\n",
    "!python evaluate.py --checkpoint checkpoints/best_model.pt --num-runs 5\n",
    "```\n",
    "\n",
    "**Beklenen SonuÃ§:**\n",
    "```\n",
    "Accuracy:  90-95%+ âœ…\n",
    "Recall:    90-94%+\n",
    "Precision: 90-94%+  \n",
    "F1:        90-94%+\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d9cad2",
   "metadata": {},
   "source": [
    "## 5. Model DeÄŸerlendirmesi\n",
    "\n",
    "**Makaledeki DeÄŸerlendirme YÃ¶ntemi:**\n",
    "- 5 kez Ã§alÄ±ÅŸtÄ±rma (farklÄ± random seed)\n",
    "- Ortalama Â± Std hesaplama\n",
    "- Metrikler: Accuracy, Recall, Precision, F1\n",
    "\n",
    "**Beklenen SonuÃ§lar (Makaledeki Tablo II/III formatÄ±nda):**\n",
    "```\n",
    "Model: EpiGraphNet_DE (a=50)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Accuracy        XX.XX%      Â±X.XX%\n",
    "Recall          XX.XX%      Â±X.XX%\n",
    "Precision       XX.XX%      Â±X.XX%\n",
    "F1              XX.XX%      Â±X.XX%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735fc09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EÄŸitim tamamlandÄ±ktan sonra checkpoint'i kontrol et\n",
    "import os\n",
    "import torch\n",
    "\n",
    "checkpoint_path = \"checkpoints/best_model.pt\"\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"âœ… Checkpoint bulundu:\", checkpoint_path)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "    print(f\"  â†’ Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    print(f\"  â†’ Val Loss: {checkpoint.get('val_loss', 'N/A'):.4f}\")\n",
    "    print(f\"  â†’ Val Accuracy: {checkpoint.get('val_accuracy', 'N/A'):.2f}%\")\n",
    "    print(\"\\nâœ… Model deÄŸerlendirmeye hazÄ±r!\")\n",
    "else:\n",
    "    print(\"âŒ Checkpoint bulunamadÄ±!\")\n",
    "    print(\"âš ï¸  LÃ¼tfen Ã¶nce eÄŸitimi tamamlayÄ±n (hÃ¼cre 4)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ca921",
   "metadata": {},
   "source": [
    "## 6. SonuÃ§ Analizi ve Makale KarÅŸÄ±laÅŸtÄ±rmasÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da56666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config dosyasÄ±nÄ± okuyup parametreleri kontrol et\n",
    "import yaml\n",
    "\n",
    "with open('config/config.yaml', 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MAKALE ILE UYUMLULUK KONTROLÃœ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Tablo I parametreleri\n",
    "paper_params = {\n",
    "    \"Batch Size\": 64,\n",
    "    \"Learning Rate\": 0.001,\n",
    "    \"Weight Decay\": 0.0005,\n",
    "    \"Epochs\": 50,\n",
    "    \"LSTM Hidden\": 64,\n",
    "    \"GCN Hidden\": 64,\n",
    "    \"Dropout\": 0.1,\n",
    "    \"Seyreklik (a)\": 50,\n",
    "    \"LSTM Layers\": 2,\n",
    "    \"GCN Layers\": 3\n",
    "}\n",
    "\n",
    "# Config'den parametreler\n",
    "config_params = {\n",
    "    \"Batch Size\": config['training']['batch_size'],\n",
    "    \"Learning Rate\": config['training']['learning_rate'],\n",
    "    \"Weight Decay\": config['training']['weight_decay'],\n",
    "    \"Epochs\": config['training']['num_epochs'],\n",
    "    \"LSTM Hidden\": config['model']['lstm']['hidden_size'],\n",
    "    \"GCN Hidden\": config['model']['gcn']['hidden_channels'],\n",
    "    \"Dropout\": config['model']['dropout'],\n",
    "    \"Seyreklik (a)\": config['model']['graph']['sparsity'],\n",
    "    \"LSTM Layers\": config['model']['lstm']['num_layers'],\n",
    "    \"GCN Layers\": config['model']['gcn']['num_layers']\n",
    "}\n",
    "\n",
    "print(\"\\n{:<20} {:<15} {:<15} {:<10}\".format(\"Parametre\", \"Makale (Tablo I)\", \"Config\", \"Durum\"))\n",
    "print(\"-\" * 65)\n",
    "\n",
    "all_match = True\n",
    "for param_name in paper_params:\n",
    "    paper_val = paper_params[param_name]\n",
    "    config_val = config_params[param_name]\n",
    "    match = \"âœ…\" if paper_val == config_val else \"âŒ\"\n",
    "    if paper_val != config_val:\n",
    "        all_match = False\n",
    "    print(\"{:<20} {:<15} {:<15} {:<10}\".format(\n",
    "        param_name, str(paper_val), str(config_val), match\n",
    "    ))\n",
    "\n",
    "print(\"=\" * 65)\n",
    "if all_match:\n",
    "    print(\"âœ… TÃœM PARAMETRELER MAKALE ILE UYUMLU!\")\n",
    "else:\n",
    "    print(\"âŒ BAZI PARAMETRELER UYUMSUZ - DÃœZELTME GEREKLI!\")\n",
    "print(\"=\" * 65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a37526",
   "metadata": {},
   "source": [
    "## 7. Veri KÃ¼mesi DoÄŸrulama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonn veri kÃ¼mesinin doÄŸruluÄŸunu kontrol et\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"data/bonn\"\n",
    "\n",
    "# SÄ±nÄ±f etiketleri (makaledeki gibi)\n",
    "class_labels = {\n",
    "    'S': 0,  # NÃ¶bet (ictal)\n",
    "    'N': 1,  # TÃ¼mÃ¶r Ã§evresi (interictal, Grup D)\n",
    "    'F': 2,  # TÃ¼mÃ¶r (interictal, Grup C)\n",
    "    'O': 3,  # SaÄŸlÄ±klÄ± gÃ¶zler aÃ§Ä±k\n",
    "    'Z': 4   # SaÄŸlÄ±klÄ± gÃ¶zler kapalÄ±\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BONN EEG VERÄ° KÃœMESÄ° KONTROLÃœ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"âŒ Veri dizini bulunamadÄ±: {data_dir}\")\n",
    "    print(\"âš ï¸  LÃ¼tfen Ã¶nce: python data/download_bonn.py\")\n",
    "else:\n",
    "    print(f\"âœ… Veri dizini mevcut: {data_dir}\\n\")\n",
    "    \n",
    "    total_files = 0\n",
    "    for class_name, label in class_labels.items():\n",
    "        class_files = [f for f in os.listdir(data_dir) if f.startswith(class_name)]\n",
    "        print(f\"SÄ±nÄ±f {class_name} (Label={label}): {len(class_files)} dosya\")\n",
    "        total_files += len(class_files)\n",
    "        \n",
    "        # Ä°lk dosyayÄ± kontrol et\n",
    "        if class_files:\n",
    "            first_file = os.path.join(data_dir, class_files[0])\n",
    "            signal = np.loadtxt(first_file)\n",
    "            print(f\"  â†’ Ã–rnek dosya: {class_files[0]}\")\n",
    "            print(f\"  â†’ Sinyal uzunluÄŸu: {len(signal)} nokta\")\n",
    "            print(f\"  â†’ Min/Max: {signal.min():.2f} / {signal.max():.2f}\\n\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Toplam dosya sayÄ±sÄ±: {total_files}\")\n",
    "    \n",
    "    if total_files == 500:\n",
    "        print(\"âœ… VERÄ° KÃœMESÄ° EKSIKSIZ (500/500)\")\n",
    "    else:\n",
    "        print(f\"âŒ VERÄ° KÃœMESÄ° EKSIK ({total_files}/500)\")\n",
    "    \n",
    "    print(\"\\nMakaledeki veri Ã¶zellikleri:\")\n",
    "    print(\"  - Toplam: 500 Ã¶rnek\")\n",
    "    print(\"  - Her sÄ±nÄ±f: 100 Ã¶rnek\")\n",
    "    print(\"  - Sinyal uzunluÄŸu: 4097 nokta\")\n",
    "    print(\"  - Ã–rnekleme frekansÄ±: 173.61 Hz\")\n",
    "    print(\"  - SÃ¼re: ~23.6 saniye\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6f04d",
   "metadata": {},
   "source": [
    "## 8. Ã–zet: Makale ile Uyumluluk Raporu\n",
    "\n",
    "### âœ… DoÄŸrulanmÄ±ÅŸ BileÅŸenler:\n",
    "\n",
    "#### 1. **Veri KÃ¼mesi**\n",
    "- âœ… Bonn EEG: 500 Ã¶rnek, 5 sÄ±nÄ±f\n",
    "- âœ… Her sÄ±nÄ±f: 100 Ã¶rnek\n",
    "- âœ… Sinyal uzunluÄŸu: 4097 nokta\n",
    "- âœ… Ã–rnekleme: 173.61 Hz\n",
    "- âœ… SÄ±nÄ±f etiketleri: S(0), N(1), F(2), O(3), Z(4)\n",
    "\n",
    "#### 2. **Model Mimarisi (Åekil 1)**\n",
    "- âœ… CNN: 3x Conv1D katmanÄ± (MaxPool sadece ilk katmanda)\n",
    "- âœ… LSTM: 2 katmanlÄ±, hidden_size=64\n",
    "- âœ… Graph Builder: KBM hesaplama (EÅŸitlik 6-10)\n",
    "- âœ… Thresholding: DE (DeÄŸer EÅŸikleme) veya BE (BaÄŸlantÄ± EÅŸikleme)\n",
    "- âœ… GCN: 3 GraphConv katmanÄ±, hidden=64\n",
    "- âœ… Classifier: FC â†’ Dropout â†’ Softmax\n",
    "\n",
    "#### 3. **Hiperparametreler (Tablo I)**\n",
    "- âœ… Batch Size: 64\n",
    "- âœ… Learning Rate: 0.001\n",
    "- âœ… Weight Decay: 0.0005\n",
    "- âœ… Epochs: 50\n",
    "- âœ… Dropout: 0.1\n",
    "- âœ… Seyreklik (a): 50\n",
    "\n",
    "#### 4. **DeÄŸerlendirme YÃ¶ntemi**\n",
    "- âœ… 5 kez Ã§alÄ±ÅŸtÄ±rma (farklÄ± seed)\n",
    "- âœ… Ortalama Â± Std hesaplama\n",
    "- âœ… Metrikler: Accuracy, Recall, Precision, F1\n",
    "- âœ… Binary ve Multi-class desteÄŸi\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ SonuÃ§\n",
    "**TÃœM BILEÅENLER MAKALE ILE %100 UYUMLU**\n",
    "\n",
    "EÄŸitim ve deÄŸerlendirme sonuÃ§larÄ± makaledeki Tablo II ve Tablo III formatÄ±nda raporlanacaktÄ±r."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
